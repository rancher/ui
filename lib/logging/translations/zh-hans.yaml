---
languageName: "简体中文"
languageContribute: "帮助翻译Rancher"

loggingPage:
  targetNav:
    experimental: 实验性
    tips:
      caseA: 当前{pageScope}日志收集未启用。
      caseB: 当前日志收集目标是<code class="text-capitalize">{currentTarget}</code>，点击下面的保存按钮将禁止当前{pageScope}的日志收集。
      caseC: 当前日志收集目标是<code class="text-capitalize">{currentTarget}</code>。
      caseD: 点击下面的保存按钮去设置<span class="text-info text-capitalize">{targetType}</span>为日志收集目标服务。
      caseE: 点击下面的保存按钮来更新<span class="text-info text-capitalize">{targetType}</span>配置。
      caseF: 没有日志收集目标服务，完成以下设置并保存<code class="text-capitalize">{targetType}</code>为日志收集目标服务。
  targetTypes:
    embedded: Embedded
    elasticsearch: Elasticsearch
    splunk: Splunk
    kafka: Kafka
    syslog: Syslog
    fluentd: Fluentd
    disable: None
  endpoint: 访问地址
  endpointPlaceholder: '例如: https://192.168.1.10:9200'
  logging: 日志收集
  clusterHeader: 集群日志收集
  projectHeader: 项目日志收集
  helpText:
    cluster: 我们将使用fluentd从每个容器收集<b>stdout/stderr</b>日志，以及在每个主机上<code>/var/log/containers/</code>路径下的日志文件，日志将被发送到被选择的目标服务。
    clusterTarget: 当前日志收集目标是<code class="text-capitalize">{clusterTargetType}</code>。如果项目日志收集启用，日志将被发送到集群目标和项目目标。
    noClusterTarget: 日志收集默认禁用
  tags:
    keyPlaceholder: '例如: foo'
    valuePlaceholder: '例如: bar'
    addActionLabel: 添加字段
  keyValueForm:
    keyPlaceholder: '例如: 192.168.1.10'
  targetKafka:
    addActionLabel: 添加代理
    host: 主机
    port: 端口
  logPreview:
    header: 日志格式预览
  additional:
    header: 其他日志配置
    fields:
      header: 自定义Log字段
      helpText: 以键值对的形式添加自定义字段，以便更好地进行过滤。
    flushInterval:
      header: 刷新时间间隔
      label: 刷新时间间隔
      placeholder: '例如: 1'
      sec: 秒
      helpText: 日志刷新频率

  elasticsearch:
    header: Elasticsearch配置
    endpointHelpText: 输入云端Elacticsearch地址，或者私有部署的Elacticsearch地址。
    endpointProtocolError: 访问地址应该以"http://"或者"https://"开头。
    endpointHostError: 请输入主机名或域名。
    xpack:
      header: X-Pack安全
      headerOptional: (可选)
      helpText: 如果您的Elasticsearch开启了X-Pack内置的本地身份验证功能，请在下面设置用户名和密码。
      username: 用户名
      usernamePlaceholder: '例如: John'
      password: 密码
      passwordPlaceholder: 密码
    indexPatterns:
      header: 索引模式
      helpText: 索引模式用于生成Elacticsearch索引。
      prefix: 前缀
      prefixPlaceholder: '例如: logstash'
      dateFormat: '日期格式:'
    generatedIndex: '生成的索引格式为: <code class="text-italic">{esIndex}</code>，默认情况下索引模式为: {indexFormat}。'
  splunk:
    header: Splunk HTTP事件收集配置
    helpText: '您可以找到如何配置Splunk HEC(HTTP事件收集器)的说明，<a href="http://docs.splunk.com/Documentation/Splunk/7.0.0/Data/UsetheHTTPEventCollector" target="_blank">点击这里</a>。'
    token: Token
    tokenPlaceholder: Your Token
    tokenHelpText: 'Token是允许日志收集程序和HTTP客户端连接到HEC的验证信息，<a href="http://docs.splunk.com/Documentation/Splunk/7.0.0/Data/UsetheHTTPEventCollector#Configure_HTTP_Event_Collector_on_Splunk_Enterprise" target="_blank">了解详情</a>。'
    source: 日志源
    sourcePlaceholder: '例如: fluentd'
    sourceHelpText: '标识事件来源的默认字段，即事件发生的位置，<a href="https://docs.splunk.com/Splexicon:Source" target="_blank">了解详情</a>。'
    index: Index
    indexPlaceholder: '例如: main'
    indexHelpText: '您在此处指定的索引必须在此令牌的允许索引列表中，<a href="https://docs.splunk.com/Splexicon:Index" target="_blank">了解详情</a>。'
  kafka:
    header: Kafka配置
    endpointType: 访问端点类型
    zookeeper: Zookeeper
    broker: Broker
    brokerTypeHelpText: 使用Zookeeper或Broker作为Kafka连接入口点。
    zookeeperHelpText: Zookeeper用于构建协调、配置管理、master检测、检测kafka集群中的节点更新。
    brokkerHelpText: Kafka集群由一个或多个Broker组成，为每个Broker配置主机和端口。
    addEndpoint: 访问地址
    topic: 主题
    topicPlaceholder: '例如: message'
    topicHelpText: 日志将发送到这个主题。
  syslog:
    endpointPlaceholder: '例如: 192.168.1.10:514'
    header: Syslog配置
    endpointHelpText: 在这里输入日志服务器的接入地址，选择TCP将显示SSL证书配置。
    program: 程序名
    programPlaceholder: '例如: MyProgram'
    programHelpText: 日志中的程序名称。
    severityHelpText: '<p class="text-info text-small">日志的严重性列表可以在这里找到<a href="https://tools.ietf.org/html/rfc5424#section-6.2.1" target="_blank">，了解详情</a>。</p>'
    severities:
      emergency: Emergency
      alert: Alert
      critical: Ctitical
      error: Error
      warning: Warning
      notice: Notice
      info: Info
      debug: Debug
    tokenHelpText: '将Token令牌添加到每个系统日志消息的结构化数据中。对于像<a href="https://help.sumologic.com/Send-Data/Sources/02Sources-for-Hosted-Collectors/Cloud-Syslog-Source" target="_blank">Sumologic</a>, <a href="https://www.loggly.com/docs/customer-token-authentication-token" target="_blank">Loggly</a>等云日志系统，您可以在其配置页面上生成Token令牌。'
  fluentd:
    header: Fluentd配置
    compress:
      label: 启用Gzip压缩
      helpText: 启用Gzip压缩可减少传输数据大小。
    endpoint:
      label: 访问地址
      placeholder: '例如: 192.168.1.10:24224'
    password:
      label: 密码
      placeholder: 用于身份验证的用户名密码
    sharedKey:
      label: 共享密钥
      placeholder: 用于身份验证的共享密钥
    standby:
      label: Use as Standby Only
    username:
      label: 用户名
      placeholder: 用于身份验证的用户名
    weight:
      label: 权重
      placeholder: 此访问地址的负载平衡权重。
    addServer: 添加Fluentd服务
    endpointHostError: 访问地址不能以http或https开头。
    endpointPortError: 访问地址需要添加端口。
    removeFluentServers: 删除此Fluentd服务
    enableTls:
      label: Use TLS
    certificate:
      label: PEM格式的CA证书
    hostname:
      label: 主机名
      placeholder: 服务器主机名
  ssl:
    sslHeader: SSL配置
    certificate:
      label: PEM格式的CA证书
    clientKey:
      label: 客户端私钥
    clientCert:
      label: 客户端证书
    clientKeyPass:
      label: 客户端私钥密码
      password:
        placeholder: 客户端私钥密码
    verify:
      label: SSL校验
      enabled: '启用'
      disabled: 禁用
    sslVersion:
      label: SSL版本
  dockerRootDir:
    header: Docker配置
    label: Docker Root Directory
    placeholder: "输入docker root Directory，默认值为{dir}"
